{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Use LLM Models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16a3611ff9aad8b0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:20:59.307199Z",
     "start_time": "2024-03-15T09:20:59.288079Z"
    }
   },
   "id": "e4fd9d85be97c661",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f246b7d393158c8e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Hugging Face & Transformers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acad38999d7de622"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain.llms import HuggingFacePipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:18:03.577776Z",
     "start_time": "2024-03-15T09:18:03.325132Z"
    }
   },
   "id": "255a17ad0ac75677",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea20a967c96743aba7c5c9b3abd71a2f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "567f9711b9d9458f84b335f75beb7f82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A: The capital of China is Beijing. \n"
     ]
    }
   ],
   "source": [
    "# Example 1: orca_mini_3b\n",
    "llm_name = \"pankajmathur/orca_mini_3b\"\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=llm_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(llm_name)\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "query = 'What is the capital of China? '\n",
    "print(local_llm(query))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:22:22.662282Z",
     "start_time": "2024-03-15T09:21:00.406910Z"
    }
   },
   "id": "38f59e69cdfad42",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "128"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:23:08.298646Z",
     "start_time": "2024-03-15T09:23:08.291604Z"
    }
   },
   "id": "b18233c454eea90c",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "267ee52912884404817ded71e22b8651"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47ec27f2158a4c2e99a3cad436a05227"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A.  北京  B.  上海  C.  广州\n",
      "\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "# Example 2: 阿里千问\n",
    "pipe = pipeline(\"text-generation\", model=\"Qwen/Qwen-1_8B\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-1_8B\", trust_remote_code=True)\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "query_cn = '中国的首都是哪里？'\n",
    "print(local_llm(query_cn))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:34:39.460644Z",
     "start_time": "2024-03-15T09:34:14.783530Z"
    }
   },
   "id": "2801323ac025005f",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LangChain"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f56c105bfb3e0afe"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f25b6313971445b29b11a0659de261ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " First, we need to know the country we are asking about. China is a country in Asia. Second, we need to know the name of the capital city of China. The capital city of China is Beijing. Finally, we can say \"Beijing is the capital city of China.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "hf = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"pankajmathur/orca_mini_3b\", \n",
    "    task=\"text-generation\", \n",
    "    pipeline_kwargs={\"max_new_tokens\": 200, \"pad_token_id\": 50256},\n",
    ")\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = prompt | hf\n",
    "\n",
    "question = \"What is the capital city of China?\"\n",
    "print(chain.invoke({\"question\": question}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:37:11.804357Z",
     "start_time": "2024-03-15T09:36:20.894780Z"
    }
   },
   "id": "2976913ba3b19cca",
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
